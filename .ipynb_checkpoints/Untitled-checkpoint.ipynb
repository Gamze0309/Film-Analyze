{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8ba365-3134-41f1-946f-b5883370eb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd87bf2e-227c-4d02-937f-f3557b7e9c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df = pd.read_csv(\"movies.csv\")\n",
    "movies_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4ad33d-c7da-49cc-a814-a7feab582674",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5383668-80fc-4ffc-a3c1-64eaec564b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize a paragraph into sentences and store in sent_tokenized\n",
    "sent_tokenized = [sent for sent in nltk.sent_tokenize(\"\"\"\n",
    "                        Today (May 19, 2016) is his only daughter's wedding. \n",
    "                        Vito Corleone is the Godfather.\n",
    "                        \"\"\")]\n",
    "\n",
    "# Word Tokenize first sentence from sent_tokenized, save as words_tokenized\n",
    "words_tokenized = [word for word in nltk.word_tokenize(sent_tokenized[0])]\n",
    "print(words_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298af772-c258-448b-bc9e-981345409ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered = [word for word in words_tokenized if re.search('[a-zA-Z]', word)]\n",
    "\n",
    "# Display filtered words to observe words after tokenization\n",
    "filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509fc648-5a0d-4ecf-8cb4-915c0f498446",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the SnowballStemmer to perform s\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "# Create an English language SnowballStemmer object\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "\n",
    "# Print filtered to observe words without stemming\n",
    "print(\"Without stemming: \", filtered)\n",
    "\n",
    "# Stem the words from filtered and store in stemmed_words\n",
    "stemmed_words = [stemmer.stem(word) for word in filtered]\n",
    "\n",
    "# Print the stemmed_words to observe words after stemming\n",
    "print(\"After stemming:   \", stemmed_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859900d4-cc72-44a8-94b8-2bd26551bc0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_stem(text):\n",
    "    \n",
    "    # Tokenize by sentence, then by word\n",
    "    tokens = [word for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent)]\n",
    "    \n",
    "    # Filter out raw tokens to remove noise\n",
    "    filtered_tokens = [token for token in tokens if re.search('[a-zA-Z]', token)]\n",
    "    \n",
    "    # Stem the filtered_tokens\n",
    "    stems = [stemmer.stem(t) for t in filtered_tokens]\n",
    "    \n",
    "    return stems\n",
    "\n",
    "words_stemmed = tokenize_and_stem(\"Today (May 19, 2016) is his only daughter's wedding.\")\n",
    "print(words_stemmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c3a764-2d0c-450f-a489-5df4750101d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import TfidfVectorizer to create TF-IDF vectors\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Instantiate TfidfVectorizer object with stopwords and tokenizer\n",
    "# parameters for efficient processing of text\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.8, max_features=200000,\n",
    "                                 min_df=0.2, stop_words='english',\n",
    "                                 use_idf=True, tokenizer=tokenize_and_stem,\n",
    "                                 ngram_range=(1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feff5b5b-cb2b-41fa-93ba-17d62141057a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and transform the tfidf_vectorizer with the \"plot\" of each movie\n",
    "# to create a vector representation of the plot summaries\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform([x for x in movies_df[\"Plot\"]])\n",
    "\n",
    "print(tfidf_matrix.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57422cb-098d-44ac-a16c-822fc38ee36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import k-means to perform clusters\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Create a KMeans object with 5 clusters and save as km\n",
    "km = KMeans(n_clusters=5)\n",
    "\n",
    "# Fit the k-means object with tfidf_matrix\n",
    "km.fit(tfidf_matrix)\n",
    "\n",
    "clusters = km.labels_.tolist()\n",
    "\n",
    "# Create a column cluster to denote the generated cluster for each movie\n",
    "movies_df[\"Cluster\"] = clusters\n",
    "\n",
    "# Display number of films per cluster (clusters from 0 to 4)\n",
    "movies_df['Cluster'].value_counts() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544993b6-dd52-4564-abae-6e2ce87895fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import cosine_similarity to calculate similarity of movie plots\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Calculate the similarity distance\n",
    "similarity_distance = 1 - cosine_similarity(tfidf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c98cd81-9c78-4182-ab7f-94b92ce691b4",
   "metadata": {},
   "source": [
    "Bos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701b7295-e5f5-4610-bf73-4921672348a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import matplotlib.pyplot for plotting graphs\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Configure matplotlib to display the output inline\n",
    "%matplotlib inline\n",
    "\n",
    "# Import modules necessary to plot dendrogram\n",
    "from scipy.cluster.hierarchy import linkage,dendrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90a4f99-6fa3-4de5-ac5e-a98f09165e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create mergings matrix \n",
    "mergings = linkage(similarity_distance, method='complete')\n",
    "\n",
    "# Plot the dendrogram, using title as label column\n",
    "dendrogram_ = dendrogram(mergings,\n",
    "               labels=[x for x in movies_df[\"Title\"]],\n",
    "               leaf_rotation=90,\n",
    "               leaf_font_size=16,\n",
    ")\n",
    "\n",
    "# Adjust the plot\n",
    "fig = plt.gcf()\n",
    "_ = [lbl.set_color('r') for lbl in plt.gca().get_xmajorticklabels()]\n",
    "fig.set_size_inches(108, 21)\n",
    "\n",
    "# Show the plotted dendrogram\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6fd11c-706f-46c2-87bb-386ef62dcf06",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig('movies_demo.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676f0d5d-6099-4887-9ac6-2ee0cfe042c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_similar(title):\n",
    "  index = movies_df[movies_df['Title'] == title].index[0]\n",
    "  vector = similarity_distance[index, :]\n",
    "  most_similar = movies_df.iloc[np.argsort(vector)[1], 1]\n",
    "  return most_similar\n",
    "print(find_similar('How Are You?')) # prints \"The Graduate\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66ce1b3-6324-4a26-9b29-ec352660c579",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
